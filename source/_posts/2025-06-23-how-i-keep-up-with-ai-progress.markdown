---
title: How I keep up with AI progress (and why you must too)
kind: article
author: Atharva Raykar
created_at: 2025-06-23 00:00:00 UTC
layout: post
---
Generative AI has been the fastest moving technology I have seen in my lifetime. Its capabilities also happen to be terribly misunderstood.

Organisations that underestimate the capabilities of AI are likely to miss out on its disruption potential. An example most visible to me is missing out on the [speed increase](https://www.youtube.com/watch?v=KVZ3vMx_aJ4) brought in by [AI coding tools](/blog/2025/05/29/ai-assisted-coding/).

Those that still view AI as mostly unreliable "stochastic parrots" will likely lose to those that understand and integrate AI effectively.

I've seen organisations also overestimate how capable AI is due to the undue hype around it. Some of this comes from the frontier labs laying out bold targets for achieving "AGI", but a lot of it comes from a slew of "influencers" and people who frankly don't know what they are talking about.

Not understanding the capabilities of the technology well enough can lead to disastrous consequences. We have already seen large [companies](https://www.youtube.com/watch?v=TwdduNZJKUM) and even [governments](https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law) ship dysfunctional or even [dangerous](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/#this-is-a-very-common-problem) AI products. Sufficiently uninformed people [misunderstand how to apply AI](https://arstechnica.com/tech-policy/2023/06/lawyers-have-real-bad-day-in-court-after-citing-fake-cases-made-up-by-chatgpt/) with real and negative consequences.

The pattern for errors of overestimation and underestimation are rooted in lack of a solid understanding of the technology and how it is evolving over time. As technologists, it is our responsibility to deeply understand emerging technology. It's good for business. More importantly, technologists should take responsibility for the consequences of what we build, and that means we must understand what the capabilities of AI are before rushing to ship something.

This is surprisingly challenging. We are in one of the most polluted information environments. If you're not being deliberate about it, you are likely to be exposed to a lot of misinformation that overstates or dismisses the capability of AI.

My sources:
* Simon Willison
* Andrej Karpathy
* Algotrained Twitter
* Nato Lambert's interconnected newsletter
* Every
* Official blogs: Anthropic, OpenAI, Meta
* Ethan Mollick
* Chip Huyen
* Eugene Yan
* swyx
* SmolAI twitter roundups
* David Crawshaw
* Janus
* Jeremy Howard
* LessWrong
* Gwern
* Dwarkesh Patel
* Wyatt Walls
* Alexander Doria
* Kwindla Kramer
* Aparna Dhinakaran
* Jo Kristian Bergum
* Erik Meijer
* Omar Khattab
* Jason Liu
* Greg Kamradt
* Gwen Shapira
* Your local AI meetup


AI drive thru issues: https://www.youtube.com/watch?v=TwdduNZJKUM
fake cases: https://arstechnica.com/tech-policy/2023/06/lawyers-have-real-bad-day-in-court-after-citing-fake-cases-made-up-by-chatgpt/
nyc AI chatbot, lawbreaker: https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law
