---
title: "Exploring text-to-SQL "
kind: article
author: Sezal Jain
created_at: 2025-04-30 00:00:00 UTC
layout: post
---
Data analysis is an important need for all organizations. But writing SQL is a time-consuming and iterative process even for a data analyst proficient in SQL. 

To assist data analysts, many natural language → SQL solutions based on LLM have been attempted in the last few years. But, no standard approaches have been established yet and generating precise SQL that is faithful to user’s intent and a database’s structure is still an open problem.

Writing SQL queries to get the required data is a core need for all organizations. Tools to generate SQL given a natural language query don’t eliminate the need for SQL knowledge/expertise completely; rather they reduce the turnaround time and enable rapid experimentation and exploration. Analysts still review and validate every query, but they spend far less time hand-coding and iterating. This isn't merely about technical convenience, it's about empowering entire teams to participate in data-driven decision-making, thereby driving business agility.

There are other business problems where LLMs can be used effectively, but we are focusing first on text-to-SQL because:

- Availability of benchmark datasets for evaluation (Bird Bench, Spider SQL etc)
- Accurate evaluation by executing the generated and reference queries
- An immediately usable product for organizations



> Is it possible to take text-to-SQL beyond a proof of concept, and create a robust product which is valuable to organizations?


One of the surveys[^1] done on text-to-SQL explores more than a 100 papers on SQL generation and the different techniques used to improve the quality/accuracy of the sql generated. At nilenso, we are exploring such techniques, looking at their advantages, ease of application and relevance for real world usecases.

### Basic Approach: Zero shot prompting with question + DB schema

The very first approach one can take for SQL generation is to put the question and the database schema into the prompt and ask to generate SQL query. This approach is definitely giving better and better results with the latest LLMs, but still has shortcomings like:

- Most orgs have quite a few tables and passing all their schema will bloat up the prompt and obscure relevant information. This can be hard to see during a POC, but you will get hallucinations when you start adding schema for >10 tables.
- Domain/Company specific information is not provided in this approach. Sometimes this information can come from data itself (eg. enums in a table etc), and is crucial to have to produce the right query.
- This doesn’t allow for any iterations or validations. Complex SQL queries are best built iteratively, which allows for better understanding and more confidence.

Because of these, we continue experimenting with different approaches to improve SQL accuracy, while keeping this approach as the **Control Group** during evaluation.

### In Context Learning

For this initial exploration, we focused on **in-context learning** (ICL) with off-the-shelf models to translate natural-language queries to SQL, deliberately excluding fine-tuning. We also reduce our reliance on detailed table and column descriptions, recognizing that such metadata is often scarce in real-world scenarios.

We are currently exploring the following approaches for ICL.

- RAG Architecture
- Declarative agentic workflow
- Reactive agentic workflow

There are common techniques we end up using across these approaches, like formatting a schema a certain way, breaking down queries etc. 

### Benchmarking

[Bird-Bench](https://bird-bench.github.io/) is an extensive cross-domain database that contains over **12,751** unique question-SQL pairs spread over different domains and datasets, with ~1500 questions in its dev-set.  For our experimentation, we have first focused on the 1500 questions in the dev-set.

A sample entry in the questions can look like:

```
  {
    "question_id": 163,
    "db_id": "financial",
    "question": "Which district has the most accounts with loan contracts finished with no problems?",
    "evidence": "status = 'A' refers to loan contracts finished with no problems",
    "SQL": "SELECT T1.A2 FROM District AS T1 INNER JOIN Account AS T2 ON T1.District_id = T2.District_id INNER JOIN Loan AS T3 ON T2.Account_id = T3.Account_id WHERE T3.status = 'A' GROUP BY T1.District_id ORDER BY COUNT(T2.Account_id) DESC LIMIT 1",
    "difficulty": "moderate"
  },
```

This gives you the input NL question as well as the reference-SQL generated by data engineers. We can now evaluate the generated SQL against the reference with different methods easily.

Some key aspects of Bird-Bench dataset make it very suitable to evaluating an application for robustness:
- Real, large databases across different domains with messy prod data, redundant columns etc.
- Varying levels of query difficulty, needing joins + nested + window + set ops and more.
- Dev set and Train set have different dbs, making sure overfitting is devalued.
- External domain knowledge is required (eg. understanding of school system, or finance data etc) where you can utilize the LLMs to the fullest.

Bird Bench dataset will be used in all our approaches as a benchmark to understand what techniques improve the solution and which dont. We will also be benchmarking on other datasets like [Spider-SQL](https://yale-lily.github.io/spider), which follows a very similar structure.

### Evaluation:

The methods to evaluate the generated vs reference SQL are broadly divided into content matching (exact string or component matching), query execution or LLM-as-judge based evaluation methods.

We focus on execution based methods for our experiments. We match the data generated by the two queries, but don’t fail evaluation in the following cases:

- The column names or order are different.
- If there are extra columns generated by the query as the additional information can be useful to the analyst
- Row order is important in some cases, not all

These evaluation metrics help us to focus on techniques which will be useful in the real world ***helping an analyst*** usecases.

We will be writing about our experiments with the different approaches, and our opinions and observations while implementing them in upcoming blogs.

[^1]: [Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL](https://arxiv.org/pdf/2406.08426v3) This is an anlaysis of recent advances in LLM-based text-to-SQL